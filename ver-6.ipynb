{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Загрузка и обработка данных","metadata":{"id":"kc4-ppijiTTj"}},{"cell_type":"code","source":"import os\n#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nimport torchtext\nfrom torchtext.data import Field, BucketIterator\n\nimport random\nimport math\nimport time\nimport numpy as np\n\nimport matplotlib\nmatplotlib.rcParams.update({'figure.figsize': (16, 12), 'font.size': 14})\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n%matplotlib inline\nfrom IPython.display import clear_output\n\nfrom nltk.tokenize import WordPunctTokenizer","metadata":{"id":"XrvAu2_TfHkI","execution":{"iopub.status.busy":"2021-07-06T13:35:25.620352Z","iopub.execute_input":"2021-07-06T13:35:25.620715Z","iopub.status.idle":"2021-07-06T13:35:25.632416Z","shell.execute_reply.started":"2021-07-06T13:35:25.620684Z","shell.execute_reply":"2021-07-06T13:35:25.631432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#! wget https://drive.google.com/uc?id=1NWYqJgeG_4883LINdEjKUr6nLQPY6Yb_ -O data.txt","metadata":{"id":"fPFyJHKai7eu","execution":{"iopub.status.busy":"2021-07-03T21:17:16.346905Z","iopub.execute_input":"2021-07-03T21:17:16.347168Z","iopub.status.idle":"2021-07-03T21:17:16.352902Z","shell.execute_reply.started":"2021-07-03T21:17:16.34714Z","shell.execute_reply":"2021-07-03T21:17:16.352168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"asUKsqOjKKnh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer_W = WordPunctTokenizer()\n\n# tokenizer is the same in both cases. This is made just for convenience\ndef tokenize_ru(x, tokenizer=tokenizer_W):\n    return tokenizer.tokenize(x.lower())\n\ndef tokenize_en(x, tokenizer=tokenizer_W):\n    return tokenizer.tokenize(x.lower())","metadata":{"id":"3eeQBY5oiXGB","execution":{"iopub.status.busy":"2021-07-06T13:35:30.153077Z","iopub.execute_input":"2021-07-06T13:35:30.153421Z","iopub.status.idle":"2021-07-06T13:35:30.159266Z","shell.execute_reply.started":"2021-07-06T13:35:30.153387Z","shell.execute_reply":"2021-07-06T13:35:30.158241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Word to vec","metadata":{"id":"ofb05NHwkKfc"}},{"cell_type":"code","source":"'''\ntokenized_en_data = []\nwith open('/content/drive/MyDrive/Colab Notebooks/Курс Stpeik DLS 2/Проект/data_ya_hw_modif_en.txt','r') as my_file_en:\n  for line in my_file_en:\n    tokenized_en_data.extend(tokenize_en(line))\n'''\nNone","metadata":{"id":"kMhyBg0RkMLR","execution":{"iopub.status.busy":"2021-07-03T21:17:16.363033Z","iopub.execute_input":"2021-07-03T21:17:16.363521Z","iopub.status.idle":"2021-07-03T21:17:16.36909Z","shell.execute_reply.started":"2021-07-03T21:17:16.363483Z","shell.execute_reply":"2021-07-03T21:17:16.368363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ntokenized_ru_data = []\nwith open('/content/drive/MyDrive/Colab Notebooks/Курс Stpeik DLS 2/Проект/data_ya_hw_modif_ru.txt','r') as my_file_ru:\n  for line in my_file_ru:\n    tokenized_ru_data.extend(tokenize_ru(line))\n'''","metadata":{"id":"9TkcHzTraSb2","outputId":"145d1d0c-df4d-4898-a333-a5b67c2d8443","execution":{"iopub.status.busy":"2021-07-03T21:17:16.370246Z","iopub.execute_input":"2021-07-03T21:17:16.370801Z","iopub.status.idle":"2021-07-03T21:17:16.381481Z","shell.execute_reply.started":"2021-07-03T21:17:16.370767Z","shell.execute_reply":"2021-07-03T21:17:16.380641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gensim.test.utils import common_texts\nimport gensim.models","metadata":{"id":"nX8SDS88kYai","execution":{"iopub.status.busy":"2021-07-06T13:35:32.619821Z","iopub.execute_input":"2021-07-06T13:35:32.620144Z","iopub.status.idle":"2021-07-06T13:35:33.020649Z","shell.execute_reply.started":"2021-07-06T13:35:32.620113Z","shell.execute_reply":"2021-07-06T13:35:33.019812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gensim.test.utils import datapath\nfrom gensim import utils\n\nclass MyCorpus:\n    \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n\n    def __init__(self, file_path):\n      self.file_path = file_path\n\n    def __iter__(self):\n        corpus_path = self.file_path\n        for line in open(corpus_path):\n            # assume there's one document per line, tokens separated by whitespace\n            yield tokenize_en(line)","metadata":{"id":"woPSfkcgsLod","execution":{"iopub.status.busy":"2021-07-06T13:35:34.835591Z","iopub.execute_input":"2021-07-06T13:35:34.83591Z","iopub.status.idle":"2021-07-06T13:35:34.841944Z","shell.execute_reply.started":"2021-07-06T13:35:34.835883Z","shell.execute_reply":"2021-07-06T13:35:34.840872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentences_en = MyCorpus('../input/400k-sentence/data_ya_hw_3_modif_sentences_en.txt')\nmodel_en = gensim.models.Word2Vec(sentences=sentences_en, vector_size=256, window=5, min_count=5, workers=4)","metadata":{"id":"Ri-yro3MmqaT","execution":{"iopub.status.busy":"2021-07-03T21:17:16.781275Z","iopub.execute_input":"2021-07-03T21:17:16.781536Z","iopub.status.idle":"2021-07-03T21:19:26.09114Z","shell.execute_reply.started":"2021-07-03T21:17:16.781511Z","shell.execute_reply":"2021-07-03T21:19:26.090274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_en.wv.most_similar('clever', topn=10)","metadata":{"id":"nkI3K9f7vcyb","outputId":"99b11b86-e143-4dce-b098-54bc5d65fe45","execution":{"iopub.status.busy":"2021-07-03T21:19:26.09307Z","iopub.execute_input":"2021-07-03T21:19:26.093431Z","iopub.status.idle":"2021-07-03T21:19:26.127819Z","shell.execute_reply.started":"2021-07-03T21:19:26.093366Z","shell.execute_reply":"2021-07-03T21:19:26.126779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#word_vectors_en = model_en.wv\n#word_vectors_en.save(\"word2vec.wordvectors\")\nmodel_en.wv.save_word2vec_format(\"word2vec_en.wordvectors\")\ndel model_en","metadata":{"id":"ppBlrwG21is0","execution":{"iopub.status.busy":"2021-07-03T21:19:26.129186Z","iopub.execute_input":"2021-07-03T21:19:26.129548Z","iopub.status.idle":"2021-07-03T21:19:34.136715Z","shell.execute_reply.started":"2021-07-03T21:19:26.129509Z","shell.execute_reply":"2021-07-03T21:19:34.135766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentences_ru = MyCorpus('../input/400k-sentence/data_ya_hw_3_modif_sentences_ru.txt')\nmodel_ru = gensim.models.Word2Vec(sentences=sentences_ru, vector_size=256, window=5, min_count=5, workers=4)","metadata":{"id":"cUeAm2rbwYYk","execution":{"iopub.status.busy":"2021-07-03T21:19:34.138096Z","iopub.execute_input":"2021-07-03T21:19:34.138486Z","iopub.status.idle":"2021-07-03T21:21:58.619204Z","shell.execute_reply.started":"2021-07-03T21:19:34.138445Z","shell.execute_reply":"2021-07-03T21:21:58.618257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_ru.wv.most_similar('квартира', topn=10)","metadata":{"id":"5B-9oQsZxt3E","outputId":"77a420bb-193e-466c-c697-3735fb192954","execution":{"iopub.status.busy":"2021-07-03T21:21:58.620534Z","iopub.execute_input":"2021-07-03T21:21:58.620977Z","iopub.status.idle":"2021-07-03T21:21:58.680129Z","shell.execute_reply.started":"2021-07-03T21:21:58.620937Z","shell.execute_reply":"2021-07-03T21:21:58.67922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#word_vectors_ru = model_ru.wv\n#word_vectors_ru.save(\"word2vec_ru.wordvectors\")\nmodel_ru.wv.save_word2vec_format(\"word2vec_ru.wordvectors\")\ndel model_ru","metadata":{"id":"lzbqqUwe1nTR","execution":{"iopub.status.busy":"2021-07-03T21:21:58.68138Z","iopub.execute_input":"2021-07-03T21:21:58.681909Z","iopub.status.idle":"2021-07-03T21:22:17.153267Z","shell.execute_reply.started":"2021-07-03T21:21:58.681869Z","shell.execute_reply":"2021-07-03T21:22:17.152446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build vocab","metadata":{"id":"xAb2NO0skTIs"}},{"cell_type":"code","source":"from torchtext.vocab import Vectors\n#https://pytorch.org/text/stable/vocab.html#vectors\n\nvectors_en = Vectors(name='../input/400ksentence35epoch/word2vec_en.wordvectors', cache='en_vec') # model_name + path = path_to_embeddings_file","metadata":{"id":"UQaajoPt2Awo","execution":{"iopub.status.busy":"2021-07-06T13:35:53.990496Z","iopub.execute_input":"2021-07-06T13:35:53.990839Z","iopub.status.idle":"2021-07-06T13:36:01.680228Z","shell.execute_reply.started":"2021-07-06T13:35:53.990803Z","shell.execute_reply":"2021-07-06T13:36:01.679094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectors_ru = Vectors(name='../input/400ksentence35epoch/word2vec_ru.wordvectors', cache='ru_vec')","metadata":{"id":"FW7sFiTZ3HON","execution":{"iopub.status.busy":"2021-07-06T13:36:07.84393Z","iopub.execute_input":"2021-07-06T13:36:07.844254Z","iopub.status.idle":"2021-07-06T13:36:22.865314Z","shell.execute_reply.started":"2021-07-06T13:36:07.844222Z","shell.execute_reply":"2021-07-06T13:36:22.864435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#https://torchtext.readthedocs.io/en/latest/data.html#torchtext.data.Field \nSRC = Field(tokenize=tokenize_ru,\n            init_token = '<sos>', \n            eos_token = '<eos>', \n            lower = True,\n            batch_first = True)\n\n# размер батча будет первой размерностью \nTRG = Field(tokenize=tokenize_en,\n            init_token = '<sos>', \n            eos_token = '<eos>', \n            lower = True,\n            batch_first = True)\n\n# https://torchtext.readthedocs.io/en/latest/data.html#tabulardataset\ndataset = torchtext.data.TabularDataset(\n    path='../input/400ksentence35epoch/data_ya_hw_3_modif.txt',\n    format='tsv',\n    fields=[('trg', TRG), ('src', SRC)]\n)","metadata":{"id":"8FtaAOjQjU0y","execution":{"iopub.status.busy":"2021-07-06T13:36:22.867861Z","iopub.execute_input":"2021-07-06T13:36:22.86821Z","iopub.status.idle":"2021-07-06T13:36:54.865033Z","shell.execute_reply.started":"2021-07-06T13:36:22.868172Z","shell.execute_reply":"2021-07-06T13:36:54.864138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(dataset.examples[23000].src)","metadata":{"id":"0u4q-nakNu0K","outputId":"f7e4b780-644d-487a-fe2b-6060aed8ad6c","execution":{"iopub.status.busy":"2021-07-06T13:36:54.866713Z","iopub.execute_input":"2021-07-06T13:36:54.867054Z","iopub.status.idle":"2021-07-06T13:36:54.874255Z","shell.execute_reply.started":"2021-07-06T13:36:54.867018Z","shell.execute_reply":"2021-07-06T13:36:54.873396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(dataset.examples[23000].trg)","metadata":{"id":"BpzItGqQKzQr","outputId":"e7aa65d8-6dd9-4122-8600-3f882287b6dc","execution":{"iopub.status.busy":"2021-07-06T13:36:54.876001Z","iopub.execute_input":"2021-07-06T13:36:54.876389Z","iopub.status.idle":"2021-07-06T13:36:54.88386Z","shell.execute_reply.started":"2021-07-06T13:36:54.876339Z","shell.execute_reply":"2021-07-06T13:36:54.882805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://stackoverflow.com/questions/48504854/python-random-getstate-and-random-setstate/48505649\nrandom.seed(42)\nst = random.getstate()\ntrain_data, test_data, valid_data  = dataset.split(split_ratio=[0.8, 0.15, 0.05], random_state = st)","metadata":{"id":"ezRiB-ReNDH7","execution":{"iopub.status.busy":"2021-07-06T13:36:54.88522Z","iopub.execute_input":"2021-07-06T13:36:54.885648Z","iopub.status.idle":"2021-07-06T13:36:55.514012Z","shell.execute_reply.started":"2021-07-06T13:36:54.885611Z","shell.execute_reply":"2021-07-06T13:36:55.513135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Number of training examples: {len(train_data.examples)}\")\nprint(f\"Number of validation examples: {len(valid_data.examples)}\")\nprint(f\"Number of testing examples: {len(test_data.examples)}\")","metadata":{"id":"JinS0BvjOu_5","outputId":"3ccfcaf7-104e-4f93-ff08-34201ed10a69","execution":{"iopub.status.busy":"2021-07-06T13:36:55.51539Z","iopub.execute_input":"2021-07-06T13:36:55.51575Z","iopub.status.idle":"2021-07-06T13:36:55.521703Z","shell.execute_reply.started":"2021-07-06T13:36:55.515712Z","shell.execute_reply":"2021-07-06T13:36:55.520578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Obtained number of examples: {len(train_data.examples) + len(valid_data.examples) + len(test_data.examples)}\")\nprint(f\"Expected number of examples: {len(dataset)}\")","metadata":{"id":"qMplC_l8b-Tt","outputId":"935ee401-6e88-4a7f-ad5b-54cb95fab690","execution":{"iopub.status.busy":"2021-07-06T13:36:55.524839Z","iopub.execute_input":"2021-07-06T13:36:55.525419Z","iopub.status.idle":"2021-07-06T13:36:55.531271Z","shell.execute_reply.started":"2021-07-06T13:36:55.525376Z","shell.execute_reply":"2021-07-06T13:36:55.530152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRG.build_vocab(train_data, min_freq = 5, vectors=vectors_en)\nSRC.build_vocab(train_data, min_freq = 5, vectors=vectors_ru)","metadata":{"id":"zpNiR4W7O0B5","execution":{"iopub.status.busy":"2021-07-06T13:36:55.533128Z","iopub.execute_input":"2021-07-06T13:36:55.533563Z","iopub.status.idle":"2021-07-06T13:37:03.48984Z","shell.execute_reply.started":"2021-07-06T13:36:55.533503Z","shell.execute_reply":"2021-07-06T13:37:03.488926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#vars(SRC.vocab)","metadata":{"id":"Ssu3wK785gH9","execution":{"iopub.status.busy":"2021-07-03T21:23:12.061959Z","iopub.execute_input":"2021-07-03T21:23:12.062413Z","iopub.status.idle":"2021-07-03T21:23:12.066132Z","shell.execute_reply.started":"2021-07-03T21:23:12.062369Z","shell.execute_reply":"2021-07-03T21:23:12.064913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Unique tokens in source (ru) vocabulary: {len(SRC.vocab)}\")\nprint(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")","metadata":{"id":"QV3a6tXZMiIK","outputId":"8fa870b5-e122-470a-fbbb-a5015c010ab8","execution":{"iopub.status.busy":"2021-07-06T13:37:03.491083Z","iopub.execute_input":"2021-07-06T13:37:03.491492Z","iopub.status.idle":"2021-07-06T13:37:03.496702Z","shell.execute_reply.started":"2021-07-06T13:37:03.491449Z","shell.execute_reply":"2021-07-06T13:37:03.495821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"v4-wY4xVNXSE","execution":{"iopub.status.busy":"2021-07-06T13:37:25.55812Z","iopub.execute_input":"2021-07-06T13:37:25.558471Z","iopub.status.idle":"2021-07-06T13:37:25.563167Z","shell.execute_reply.started":"2021-07-06T13:37:25.558433Z","shell.execute_reply":"2021-07-06T13:37:25.561867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _len_sort_key(x):\n    return len(x.src)\n\nBATCH_SIZE = 100\n\ntrain_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n    (train_data, valid_data, test_data), \n    batch_size = BATCH_SIZE, \n    device = device,\n    sort_key=_len_sort_key\n)","metadata":{"id":"kbMQ4a6qNlxI","execution":{"iopub.status.busy":"2021-07-06T13:37:27.968917Z","iopub.execute_input":"2021-07-06T13:37:27.969245Z","iopub.status.idle":"2021-07-06T13:37:27.977942Z","shell.execute_reply.started":"2021-07-06T13:37:27.969214Z","shell.execute_reply":"2021-07-06T13:37:27.976741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n!pip install GPUtil\n\nimport torch\nfrom GPUtil import showUtilization as gpu_usage\nfrom numba import cuda\n\ndef free_gpu_cache():\n    print(\"Initial GPU Usage\")\n    gpu_usage()                             \n\n    torch.cuda.empty_cache()\n\n    cuda.select_device(0)\n    cuda.close()\n    cuda.select_device(0)\n\n    print(\"GPU Usage after emptying the cache\")\n    gpu_usage()\n\nfree_gpu_cache()\n'''\nNone","metadata":{"execution":{"iopub.status.busy":"2021-07-03T21:23:12.429334Z","iopub.execute_input":"2021-07-03T21:23:12.429721Z","iopub.status.idle":"2021-07-03T21:23:12.433625Z","shell.execute_reply.started":"2021-07-03T21:23:12.429683Z","shell.execute_reply":"2021-07-03T21:23:12.432583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#vars(vars(SRC)['vocab'])","metadata":{"id":"UoeMt-v_QDnB","execution":{"iopub.status.busy":"2021-07-03T21:23:12.435047Z","iopub.execute_input":"2021-07-03T21:23:12.435667Z","iopub.status.idle":"2021-07-03T21:23:12.441745Z","shell.execute_reply.started":"2021-07-03T21:23:12.43557Z","shell.execute_reply":"2021-07-03T21:23:12.440977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#vars(next(iter(train_iterator)))","metadata":{"id":"DHBVvcdFNwT_","execution":{"iopub.status.busy":"2021-07-03T21:23:12.442937Z","iopub.execute_input":"2021-07-03T21:23:12.443329Z","iopub.status.idle":"2021-07-03T21:23:12.450264Z","shell.execute_reply.started":"2021-07-03T21:23:12.443248Z","shell.execute_reply":"2021-07-03T21:23:12.449531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vars(next(iter(train_iterator)))['src'][0]","metadata":{"id":"xTXkiK1pPt5s","outputId":"336860e9-d019-48ac-f1dc-6ccc97c6191e","execution":{"iopub.status.busy":"2021-07-03T21:23:12.451581Z","iopub.execute_input":"2021-07-03T21:23:12.452105Z","iopub.status.idle":"2021-07-03T21:23:17.129515Z","shell.execute_reply.started":"2021-07-03T21:23:12.452068Z","shell.execute_reply":"2021-07-03T21:23:17.128713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"id":"jfsexRn2RRRy"}},{"cell_type":"markdown","source":"# Model","metadata":{"id":"PSJSKbZCR75_"}},{"cell_type":"markdown","source":"## Encoder","metadata":{"id":"NJjUtK9HVSo5"}},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, \n                 input_dim, \n                 hid_dim, \n                 n_layers, \n                 n_heads, \n                 pf_dim,\n                 dropout, \n                 device,\n                 max_length = 300):\n        super().__init__()\n\n        self.device = device\n        \n        # эмбеддинги токенов\n        self.tok_embedding = nn.Embedding(input_dim, hid_dim).from_pretrained(SRC.vocab.vectors)\n\n        # positional эмбеддинги. max_length - максимальное количество слов в предложении\n        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n        \n        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \n                                                  n_heads, \n                                                  pf_dim,\n                                                  dropout, \n                                                  device) \n                                     for _ in range(n_layers)])\n        \n        self.dropout = nn.Dropout(dropout)\n        \n        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n        \n    def forward(self, src, src_mask):\n        \n        #src = [batch size, src len]\n        #src_mask = [batch size, 1, 1, src len]\n        \n        batch_size = src.shape[0]\n        src_len = src.shape[1]\n        \n        # определяем позиции слов, которые затем будут поданы на вход pos_embedding. Слова нумеруются от 0 до src_len-1\n        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n        \n        #pos = [batch size, src len]\n        \n        # по идее мы должны просто сложить позиционный и обычные эмбеддинги. Но в данном обычные эмбеддинги мы еще домножаем на корень \n        # из размерности, чтобы нормы обоих эмбеддиногов были одинаковы.\n\n        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n        \n        #src = [batch size, src len, hid dim]\n        \n        # src_mask ставит в соответствие токену единицу, если это не <pad> и ноль, если это <pad>\n        for layer in self.layers:\n            src = layer(src, src_mask)\n            \n        #src = [batch size, src len, hid dim]\n            \n        return src","metadata":{"id":"xL5lSMvxR5T_","execution":{"iopub.status.busy":"2021-07-06T13:37:33.05218Z","iopub.execute_input":"2021-07-06T13:37:33.052527Z","iopub.status.idle":"2021-07-06T13:37:33.061853Z","shell.execute_reply.started":"2021-07-06T13:37:33.052494Z","shell.execute_reply":"2021-07-06T13:37:33.06074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EncoderLayer(nn.Module):\n    def __init__(self, \n                 hid_dim, \n                 n_heads, \n                 pf_dim,  \n                 dropout, \n                 device):\n        super().__init__()\n        \n        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n                                                                     pf_dim, \n                                                                     dropout)\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, src, src_mask):\n        \n        #src = [batch size, src len, hid dim]\n        #src_mask = [batch size, 1, 1, src len] \n                \n        #self attention\n        # k, q и v получаются из src \n        _src, _ = self.self_attention(src, src, src, src_mask)\n        \n        #dropout, residual connection and layer norm\n        src = self.self_attn_layer_norm(src + self.dropout(_src))\n        \n        #src = [batch size, src len, hid dim]\n        \n        #positionwise feedforward\n        _src = self.positionwise_feedforward(src)\n        \n        #dropout, residual and layer norm\n        src = self.ff_layer_norm(src + self.dropout(_src))\n        \n        #src = [batch size, src len, hid dim]\n        \n        return src","metadata":{"id":"USHdv6Jtj5fV","execution":{"iopub.status.busy":"2021-07-06T13:37:35.910691Z","iopub.execute_input":"2021-07-06T13:37:35.911041Z","iopub.status.idle":"2021-07-06T13:37:35.918239Z","shell.execute_reply.started":"2021-07-06T13:37:35.911007Z","shell.execute_reply":"2021-07-06T13:37:35.91742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Attention","metadata":{"id":"qJdRYFPIkYKq"}},{"cell_type":"code","source":"class MultiHeadAttentionLayer(nn.Module):\n    def __init__(self, hid_dim, n_heads, dropout, device):\n        super().__init__()\n        \n        assert hid_dim % n_heads == 0\n        \n        self.hid_dim = hid_dim\n        self.n_heads = n_heads\n        self.head_dim = hid_dim // n_heads\n        \n        # как я понял, здесь используются не различные матрицы, но одна и та же\n        self.fc_q = nn.Linear(hid_dim, hid_dim)\n        self.fc_k = nn.Linear(hid_dim, hid_dim)\n        self.fc_v = nn.Linear(hid_dim, hid_dim)\n        \n        self.fc_o = nn.Linear(hid_dim, hid_dim)\n        \n        self.dropout = nn.Dropout(dropout)\n        \n        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n        \n    def forward(self, query, key, value, mask = None):\n        \n        batch_size = query.shape[0]\n        \n        #query = [batch size, query len, hid dim]\n        #key = [batch size, key len, hid dim]\n        #value = [batch size, value len, hid dim]\n                \n        Q = self.fc_q(query)\n        K = self.fc_k(key)\n        V = self.fc_v(value)\n        \n        #Q = [batch size, query len, hid dim]\n        #K = [batch size, key len, hid dim]\n        #V = [batch size, value len, hid dim]\n                \n        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n        \n        #Q = [batch size, n heads, query len, head dim]\n        #K = [batch size, n heads, key len, head dim]\n        #V = [batch size, n heads, value len, head dim]\n\n        # K.permute(0, 1, 3, 2) - транспонирование нужных осей       \n        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n        \n        #energy = [batch size, n heads, query len, key len]\n        \n        if mask is not None:\n            # мы хотим применить softmax к energy. Но перед этим нужно сказать, что удельный вес <pad> токенов очень мал, как я понял\n            energy = energy.masked_fill(mask == 0, -1e10)\n\n        # [batch size, 1, trg len, trg len]\n        \n        attention = torch.softmax(energy, dim = -1)\n                \n        #attention = [batch size, n heads, query len, key len]\n                \n        x = torch.matmul(self.dropout(attention), V)\n        \n        #x = [batch size, n heads, query len, head dim]\n        \n        # .contiguous() переупаковывает данные так, чтобы получившейся тензор стал contiguous\n        x = x.permute(0, 2, 1, 3).contiguous()\n        \n        #x = [batch size, query len, n heads, head dim]\n        \n        x = x.view(batch_size, -1, self.hid_dim)\n        \n        #x = [batch size, query len, hid dim]\n        \n        x = self.fc_o(x)\n        \n        #x = [batch size, query len, hid dim]\n        \n        return x, attention","metadata":{"id":"u1AvPer1j8Iu","execution":{"iopub.status.busy":"2021-07-06T13:37:38.275231Z","iopub.execute_input":"2021-07-06T13:37:38.275606Z","iopub.status.idle":"2021-07-06T13:37:38.289748Z","shell.execute_reply.started":"2021-07-06T13:37:38.275572Z","shell.execute_reply":"2021-07-06T13:37:38.288775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## FF layer ","metadata":{"id":"l32kKTY0kb1g"}},{"cell_type":"code","source":"class PositionwiseFeedforwardLayer(nn.Module):\n    def __init__(self, hid_dim, pf_dim, dropout):\n        super().__init__()\n        \n        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n        \n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x):\n        \n        #x = [batch size, seq len, hid dim]\n        \n        x = self.dropout(torch.relu(self.fc_1(x)))\n        \n        #x = [batch size, seq len, pf dim]\n        \n        x = self.fc_2(x)\n        \n        #x = [batch size, seq len, hid dim]\n        \n        return x","metadata":{"id":"dTfAvkStj-k7","execution":{"iopub.status.busy":"2021-07-06T13:37:40.881615Z","iopub.execute_input":"2021-07-06T13:37:40.881939Z","iopub.status.idle":"2021-07-06T13:37:40.889231Z","shell.execute_reply.started":"2021-07-06T13:37:40.881908Z","shell.execute_reply":"2021-07-06T13:37:40.887226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Decoder","metadata":{"id":"n-sxCiQKkCWP"}},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, \n                 output_dim, \n                 hid_dim, \n                 n_layers, \n                 n_heads, \n                 pf_dim, \n                 dropout, \n                 device,\n                 max_length = 300):\n        super().__init__()\n        \n        self.device = device\n        \n        self.tok_embedding = nn.Embedding(output_dim, hid_dim).from_pretrained(TRG.vocab.vectors)\n        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n        \n        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \n                                                  n_heads, \n                                                  pf_dim, \n                                                  dropout, \n                                                  device)\n                                     for _ in range(n_layers)])\n        \n        self.fc_out = nn.Linear(hid_dim, output_dim)\n        \n        self.dropout = nn.Dropout(dropout)\n        \n        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n        \n    def forward(self, trg, enc_src, trg_mask, src_mask):\n        \n        #trg = [batch size, trg len]\n        #enc_src = [batch size, src len, hid dim]\n        #trg_mask = [batch size, 1, trg len, trg len]\n        #src_mask = [batch size, 1, 1, src len]\n                \n        batch_size = trg.shape[0]\n        trg_len = trg.shape[1]\n        \n        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n                            \n        #pos = [batch size, trg len]\n\n        # see https://discuss.pytorch.org/t/google-colab-runtimeerror-cuda-error-device-side-assert-triggered/69559    \n        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n                \n        #trg = [batch size, trg len, hid dim]\n        \n        for layer in self.layers:\n            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n        \n        #trg = [batch size, trg len, hid dim]\n        #attention = [batch size, n heads, trg len, src len]\n        \n        output = self.fc_out(trg)\n        \n        #output = [batch size, trg len, output dim]\n            \n        return output, attention","metadata":{"id":"pw5VeDGRkBIA","execution":{"iopub.status.busy":"2021-07-06T13:37:43.060424Z","iopub.execute_input":"2021-07-06T13:37:43.060765Z","iopub.status.idle":"2021-07-06T13:37:43.070873Z","shell.execute_reply.started":"2021-07-06T13:37:43.060734Z","shell.execute_reply":"2021-07-06T13:37:43.06981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DecoderLayer(nn.Module):\n    def __init__(self, \n                 hid_dim, \n                 n_heads, \n                 pf_dim, \n                 dropout, \n                 device):\n        super().__init__()\n        \n        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n                                                                     pf_dim, \n                                                                     dropout)\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, trg, enc_src, trg_mask, src_mask):\n        \n        #trg = [batch size, trg len, hid dim]\n        #enc_src = [batch size, src len, hid dim]\n        #trg_mask = [batch size, 1, trg len, trg len]\n        #src_mask = [batch size, 1, 1, src len]\n        \n        # обратим внимание на различные размерности trg_mask и src_mask\n        # trg_mask это, видимо, нижнетреугольная матриаца из лекции (сл. 47) \n\n        #self attention\n        # собственный attention декодера\n        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n        \n        #dropout, residual connection and layer norm\n\n        \n        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n            \n        #trg = [batch size, trg len, hid dim]\n            \n        #encoder attention\n        # attention между энкодером и декодером\n        # некоторые векторы мы берем из энкодера, а некоторые из декодера\n        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n        \n        #dropout, residual connection and layer norm\n        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n                    \n        #trg = [batch size, trg len, hid dim]\n        \n        #positionwise feedforward\n        _trg = self.positionwise_feedforward(trg)\n        \n        #dropout, residual and layer norm\n        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n        \n        #trg = [batch size, trg len, hid dim]\n        #attention = [batch size, n heads, trg len, src len]\n        \n        return trg, attention","metadata":{"id":"pNFp-7DrkF4Q","execution":{"iopub.status.busy":"2021-07-06T13:37:45.556452Z","iopub.execute_input":"2021-07-06T13:37:45.556776Z","iopub.status.idle":"2021-07-06T13:37:45.565811Z","shell.execute_reply.started":"2021-07-06T13:37:45.556746Z","shell.execute_reply":"2021-07-06T13:37:45.564797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Seq2Seq","metadata":{"id":"GiB8tej_kKHk"}},{"cell_type":"code","source":"class Seq2Seq(nn.Module):\n    def __init__(self, \n                 encoder, \n                 decoder, \n                 src_pad_idx, \n                 trg_pad_idx, \n                 device):\n        super().__init__()\n        \n        self.encoder = encoder\n        self.decoder = decoder\n        self.src_pad_idx = src_pad_idx\n        self.trg_pad_idx = trg_pad_idx\n        self.device = device\n        \n    def make_src_mask(self, src):\n        \n        #src = [batch size, src len]\n        \n        # см. семинар 1.t.28.00.\n        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n\n        #src_mask = [batch size, 1, 1, src len]\n\n        return src_mask\n    \n    def make_trg_mask(self, trg):\n        \n        #trg = [batch size, trg len]\n        \n        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n        \n        #trg_pad_mask = [batch size, 1, 1, trg len]\n        \n        trg_len = trg.shape[1]\n        \n        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n        \n        #trg_sub_mask = [trg len, trg len]\n\n        # перед конъюнкцией еще нужно выполнить broadcasting для trg_sub_mask и сделать ее размерность равной [batch_size, 1, trg_len, trg_len]\n        # на самом деле у trg_pad_mask тоже произойдет broadcasting по третьей оси. То есть по данной оси выполнится repeat \n        # наконец по двум последним осям выполнится конъюнкция, как я понял\n\n        trg_mask = trg_pad_mask & trg_sub_mask\n        \n        #trg_mask = [batch size, 1, trg len, trg len]\n        \n        return trg_mask\n\n    def forward(self, src, trg):\n        \n        #src = [batch size, src len]\n        #trg = [batch size, trg len]\n                \n        src_mask = self.make_src_mask(src)\n        trg_mask = self.make_trg_mask(trg)\n        \n        #src_mask = [batch size, 1, 1, src len]\n        #trg_mask = [batch size, 1, trg len, trg len]\n        \n        enc_src = self.encoder(src, src_mask)\n        \n        #enc_src = [batch size, src len, hid dim]\n                \n        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n        \n        #output = [batch size, trg len, output dim]\n        #attention = [batch size, n heads, trg len, src len]\n        \n        return output, attention","metadata":{"id":"GDCEas_YkIkl","execution":{"iopub.status.busy":"2021-07-06T13:37:47.718956Z","iopub.execute_input":"2021-07-06T13:37:47.71927Z","iopub.status.idle":"2021-07-06T13:37:47.728076Z","shell.execute_reply.started":"2021-07-06T13:37:47.71924Z","shell.execute_reply":"2021-07-06T13:37:47.727275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training routines","metadata":{"id":"TeUj9nPvlY7B"}},{"cell_type":"markdown","source":"Model parameters","metadata":{"id":"SdyvcCrGlbQU"}},{"cell_type":"code","source":"INPUT_DIM = len(SRC.vocab)\nOUTPUT_DIM = len(TRG.vocab)\nHID_DIM = 256\nENC_LAYERS = 4\nDEC_LAYERS = 4\nENC_HEADS = 8\nDEC_HEADS = 8\nENC_PF_DIM = 512\nDEC_PF_DIM = 512\nENC_DROPOUT = 0.1\nDEC_DROPOUT = 0.1\n\nenc = Encoder(INPUT_DIM, \n              HID_DIM, \n              ENC_LAYERS, \n              ENC_HEADS, \n              ENC_PF_DIM, \n              ENC_DROPOUT, \n              device)\n\ndec = Decoder(OUTPUT_DIM, \n              HID_DIM, \n              DEC_LAYERS, \n              DEC_HEADS, \n              DEC_PF_DIM, \n              DEC_DROPOUT, \n              device)","metadata":{"id":"E7tdAZykkPCg","execution":{"iopub.status.busy":"2021-07-06T13:37:52.427792Z","iopub.execute_input":"2021-07-06T13:37:52.428118Z","iopub.status.idle":"2021-07-06T13:37:57.136185Z","shell.execute_reply.started":"2021-07-06T13:37:52.428086Z","shell.execute_reply":"2021-07-06T13:37:57.135218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\nTRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n\nmodel = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)","metadata":{"id":"hvgqc82yljzk","execution":{"iopub.status.busy":"2021-07-06T13:37:57.137633Z","iopub.execute_input":"2021-07-06T13:37:57.13798Z","iopub.status.idle":"2021-07-06T13:37:57.201101Z","shell.execute_reply.started":"2021-07-06T13:37:57.137942Z","shell.execute_reply":"2021-07-06T13:37:57.200338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f'The model has {count_parameters(model):,} trainable parameters')","metadata":{"id":"7eOO80Pblu1q","outputId":"def7f95c-07f2-466b-82d5-d0c41e2c91e7","execution":{"iopub.status.busy":"2021-07-06T13:37:59.023029Z","iopub.execute_input":"2021-07-06T13:37:59.023378Z","iopub.status.idle":"2021-07-06T13:37:59.030651Z","shell.execute_reply.started":"2021-07-06T13:37:59.023325Z","shell.execute_reply":"2021-07-06T13:37:59.029677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Initialize weights","metadata":{"id":"sXrxYYf0mLpQ"}},{"cell_type":"code","source":"def initialize_weights(m):\n    if hasattr(m, 'weight') and m.weight.dim() > 1 and type(m) != nn.Embedding:\n        nn.init.xavier_uniform_(m.weight.data)","metadata":{"id":"j4GoIqNllxNb","execution":{"iopub.status.busy":"2021-07-06T13:38:05.966783Z","iopub.execute_input":"2021-07-06T13:38:05.96711Z","iopub.status.idle":"2021-07-06T13:38:05.971215Z","shell.execute_reply.started":"2021-07-06T13:38:05.96708Z","shell.execute_reply":"2021-07-06T13:38:05.970417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.apply(initialize_weights);","metadata":{"id":"0WInLjwbl0fN","execution":{"iopub.status.busy":"2021-07-03T21:23:17.793327Z","iopub.execute_input":"2021-07-03T21:23:17.793706Z","iopub.status.idle":"2021-07-03T21:23:17.806593Z","shell.execute_reply.started":"2021-07-03T21:23:17.793671Z","shell.execute_reply":"2021-07-03T21:23:17.805662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Set learning rate and loss function","metadata":{"id":"tBZOXgLEmQVO"}},{"cell_type":"code","source":"from torch.optim.lr_scheduler import ReduceLROnPlateau\n\n\nLEARNING_RATE = 1e-4 # initial lr5e-4\n\noptimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n\n#https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html\nscheduler = ReduceLROnPlateau(optimizer, 'min', factor = 0.3, patience = 1)\n","metadata":{"id":"AqZtuvLKmJz7","execution":{"iopub.status.busy":"2021-07-06T13:38:32.464908Z","iopub.execute_input":"2021-07-06T13:38:32.465257Z","iopub.status.idle":"2021-07-06T13:38:32.475277Z","shell.execute_reply.started":"2021-07-06T13:38:32.465214Z","shell.execute_reply":"2021-07-06T13:38:32.474446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)","metadata":{"id":"LHODgklmmKS6","execution":{"iopub.status.busy":"2021-07-06T13:38:34.819984Z","iopub.execute_input":"2021-07-06T13:38:34.82031Z","iopub.status.idle":"2021-07-06T13:38:34.824207Z","shell.execute_reply.started":"2021-07-06T13:38:34.820278Z","shell.execute_reply":"2021-07-06T13:38:34.823297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training function","metadata":{"id":"2M4n5JHomyBS"}},{"cell_type":"code","source":"from IPython.core.debugger import set_trace\n\ndef train(model, iterator, optimizer, criterion, clip, train_history=None, valid_history=None):\n    \n    model.train()\n    \n    epoch_loss = 0\n    history = []\n    for i, batch in enumerate(iterator):\n        \n        src = batch.src\n        trg = batch.trg\n        \n        optimizer.zero_grad()\n        \n        # не используем <eos>\n        output, _ = model(src, trg[:,:-1])\n                \n        #output = [batch size, trg len - 1, output dim]\n        #trg = [batch size, trg len]\n            \n        output_dim = output.shape[-1]\n\n        # при вычислении ошибки мы не смотрим на <sos>    \n        output = output.contiguous().view(-1, output_dim)\n        trg = trg[:,1:].contiguous().view(-1)\n                \n        #output = [batch size * trg len - 1, output dim]\n        #trg = [batch size * trg len - 1]\n\n        #set_trace()    \n        loss = criterion(output, trg)\n        \n        loss.backward()\n        \n        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n        \n        optimizer.step()\n        \n        epoch_loss += loss.item()\n\n        history.append(loss.cpu().data.numpy())\n        if (i+1)%100==0:\n            fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n\n            clear_output(True)\n            ax[0].plot(history, label='train loss')\n            ax[0].set_xlabel('Batch')\n            ax[0].set_title('Train loss')\n            if train_history is not None:\n                ax[1].plot(train_history, label='general train history')\n                ax[1].set_xlabel('Epoch')\n            if valid_history is not None:\n                ax[1].plot(valid_history, label='general valid history')\n            plt.legend()\n            \n            plt.show()\n        \n    return epoch_loss / len(iterator)","metadata":{"id":"b4UfuvAQmWOm","execution":{"iopub.status.busy":"2021-07-06T13:38:38.425328Z","iopub.execute_input":"2021-07-06T13:38:38.425697Z","iopub.status.idle":"2021-07-06T13:38:38.436248Z","shell.execute_reply.started":"2021-07-06T13:38:38.425665Z","shell.execute_reply":"2021-07-06T13:38:38.435449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Evaluation","metadata":{"id":"Xibd-CX-m22v"}},{"cell_type":"code","source":"def evaluate(model, iterator, criterion):\n    \n    model.eval()\n    \n    epoch_loss = 0\n    \n    with torch.no_grad():\n    \n        for i, batch in enumerate(iterator):\n\n            src = batch.src\n            trg = batch.trg\n\n            output, _ = model(src, trg[:,:-1])\n            \n            #output = [batch size, trg len - 1, output dim]\n            #trg = [batch size, trg len]\n            \n            output_dim = output.shape[-1]\n            \n            output = output.contiguous().view(-1, output_dim)\n            trg = trg[:,1:].contiguous().view(-1)\n            \n            #output = [batch size * trg len - 1, output dim]\n            #trg = [batch size * trg len - 1]\n            \n            loss = criterion(output, trg)\n\n            epoch_loss += loss.item()\n        \n    return epoch_loss / len(iterator)","metadata":{"id":"1udrbM-Vm0UG","execution":{"iopub.status.busy":"2021-07-06T13:38:41.742172Z","iopub.execute_input":"2021-07-06T13:38:41.742568Z","iopub.status.idle":"2021-07-06T13:38:41.749412Z","shell.execute_reply.started":"2021-07-06T13:38:41.742532Z","shell.execute_reply":"2021-07-06T13:38:41.748206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def epoch_time(start_time, end_time):\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time / 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs","metadata":{"id":"JF5KOEBYm6Hz","execution":{"iopub.status.busy":"2021-07-06T14:03:47.3161Z","iopub.execute_input":"2021-07-06T14:03:47.31644Z","iopub.status.idle":"2021-07-06T14:03:47.32204Z","shell.execute_reply.started":"2021-07-06T14:03:47.316408Z","shell.execute_reply":"2021-07-06T14:03:47.320825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Actual training","metadata":{"id":"qSGJNHiFnKOV"}},{"cell_type":"code","source":"model.load_state_dict(torch.load('../input/400ksentence35epoch/best-val-model_35_epoch.pt'))\n\ntest_loss = evaluate(model, test_iterator, criterion)\n\nprint(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')","metadata":{"execution":{"iopub.status.busy":"2021-07-06T13:39:32.064616Z","iopub.execute_input":"2021-07-06T13:39:32.064954Z","iopub.status.idle":"2021-07-06T13:39:44.909388Z","shell.execute_reply.started":"2021-07-06T13:39:32.064924Z","shell.execute_reply":"2021-07-06T13:39:44.908372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, _, bleu_score = calculate_bleu_alt(test_iterator, SRC, TRG, model, device)\n\nprint(f'BLEU score = {bleu_score*100:.2f}')","metadata":{"execution":{"iopub.status.busy":"2021-07-06T13:39:50.316246Z","iopub.execute_input":"2021-07-06T13:39:50.316615Z","iopub.status.idle":"2021-07-06T13:47:13.596386Z","shell.execute_reply.started":"2021-07-06T13:39:50.316583Z","shell.execute_reply":"2021-07-06T13:47:13.595461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_history = []\nvalid_history = []\n\nN_EPOCHS = 50\nCLIP = 1\n\nbest_valid_loss = float('inf')\n\nfor epoch in range(N_EPOCHS):\n    \n    start_time = time.time()\n    \n    train_loss = train(model, train_iterator, optimizer, criterion, CLIP, train_history, valid_history)\n    valid_loss = evaluate(model, valid_iterator, criterion)\n    scheduler.step(valid_loss)\n\n    end_time = time.time()\n    \n    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n    \n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), 'best-val-model.pt')\n    \n    train_history.append(train_loss)\n    valid_history.append(valid_loss)\n    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')","metadata":{"id":"WJICvCNwm80U","outputId":"ecd7d90b-7d83-4d9a-ec71-bdf56a0a71a6","execution":{"iopub.status.busy":"2021-07-06T14:03:54.177775Z","iopub.execute_input":"2021-07-06T14:03:54.17812Z","iopub.status.idle":"2021-07-06T17:24:01.936237Z","shell.execute_reply.started":"2021-07-06T14:03:54.178087Z","shell.execute_reply":"2021-07-06T17:24:01.933468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load('best-val-model.pt'))\n\ntest_loss = evaluate(model, test_iterator, criterion)\n\nprint(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')","metadata":{"id":"YP-sJCk9nPg-","execution":{"iopub.status.busy":"2021-07-06T17:24:10.793236Z","iopub.execute_input":"2021-07-06T17:24:10.793595Z","iopub.status.idle":"2021-07-06T17:24:19.062012Z","shell.execute_reply.started":"2021-07-06T17:24:10.793562Z","shell.execute_reply":"2021-07-06T17:24:19.061086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{"id":"6Votm0m0nZsN"}},{"cell_type":"markdown","source":"## One sentence translate","metadata":{"id":"oib41tuvoJRN"}},{"cell_type":"code","source":"# one sentence translate\ndef translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n    \n    model.eval()\n        \n    if isinstance(sentence, str):\n        nlp = spacy.load('de_core_news_sm')\n        tokens = [token.text.lower() for token in nlp(sentence)]\n    else:\n        tokens = [token.lower() for token in sentence]\n\n    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n        \n    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n\n    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n    \n    src_mask = model.make_src_mask(src_tensor)\n    \n    with torch.no_grad():\n        enc_src = model.encoder(src_tensor, src_mask)\n\n    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n\n    for i in range(max_len):\n\n        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n\n        trg_mask = model.make_trg_mask(trg_tensor)\n        \n        with torch.no_grad():\n            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n        \n        pred_token = output.argmax(2)[:,-1].item()\n        \n        trg_indexes.append(pred_token)\n\n        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n            break\n    \n    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n    \n    return trg_tokens[1:], attention","metadata":{"id":"egDXQpFFnWuS","execution":{"iopub.status.busy":"2021-07-06T17:24:34.269233Z","iopub.execute_input":"2021-07-06T17:24:34.269593Z","iopub.status.idle":"2021-07-06T17:24:34.279176Z","shell.execute_reply.started":"2021-07-06T17:24:34.269561Z","shell.execute_reply":"2021-07-06T17:24:34.278384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## BLEU score","metadata":{"id":"aWB4rRhKoMTh"}},{"cell_type":"code","source":"def translate_sentence_vectorized(src_tensor, src_field, trg_field, model, device, max_len=50):\n    assert isinstance(src_tensor, torch.Tensor)\n\n    model.eval()\n    src_mask = model.make_src_mask(src_tensor)\n\n    with torch.no_grad():\n        enc_src = model.encoder(src_tensor, src_mask)\n    # enc_src = [batch_sz, src_len, hid_dim]\n\n    trg_indexes = [[trg_field.vocab.stoi[trg_field.init_token]] for _ in range(len(src_tensor))]\n    # Even though some examples might have been completed by producing a <eos> token\n    # we still need to feed them through the model because other are not yet finished\n    # and all examples act as a batch. Once every single sentence prediction encounters\n    # <eos> token, then we can stop predicting.\n    translations_done = [0] * len(src_tensor)\n    for i in range(max_len):\n        trg_tensor = torch.LongTensor(trg_indexes).to(device)\n        trg_mask = model.make_trg_mask(trg_tensor)\n        with torch.no_grad():\n            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n        pred_tokens = output.argmax(2)[:,-1]\n        for i, pred_token_i in enumerate(pred_tokens):\n            trg_indexes[i].append(pred_token_i)\n            if pred_token_i == trg_field.vocab.stoi[trg_field.eos_token]:\n                translations_done[i] = 1\n        if all(translations_done):\n            break\n\n    # Iterate through each predicted example one by one;\n    # Cut-off the portion including the after the <eos> token\n    pred_sentences = []\n    for trg_sentence in trg_indexes:\n        pred_sentence = []\n        for i in range(1, len(trg_sentence)):\n            if trg_sentence[i] == trg_field.vocab.stoi[trg_field.eos_token]:\n                break\n            pred_sentence.append(trg_field.vocab.itos[trg_sentence[i]])\n        pred_sentences.append(pred_sentence)\n\n    return pred_sentences, attention","metadata":{"id":"mfIpjsirnqhr","execution":{"iopub.status.busy":"2021-07-06T17:24:36.36061Z","iopub.execute_input":"2021-07-06T17:24:36.360925Z","iopub.status.idle":"2021-07-06T17:24:36.370388Z","shell.execute_reply.started":"2021-07-06T17:24:36.360895Z","shell.execute_reply":"2021-07-06T17:24:36.369537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchtext.data.metrics import bleu_score\nfrom tqdm.notebook import tqdm\n\ndef calculate_bleu_alt(iterator, src_field, trg_field, model, device, max_len = 50):\n    trgs = []\n    pred_trgs = []\n    with torch.no_grad():\n        for batch in tqdm(iterator):\n            src = batch.src\n            trg = batch.trg\n            _trgs = []\n            for sentence in trg:\n                tmp = []\n                # Start from the first token which skips the <start> token\n                for i in sentence[1:]:\n                    # Targets are padded. So stop appending as soon as a padding or eos token is encountered\n                    if i == trg_field.vocab.stoi[trg_field.eos_token] or i == trg_field.vocab.stoi[trg_field.pad_token]:\n                        break\n                    tmp.append(trg_field.vocab.itos[i])\n                _trgs.append([tmp])\n            trgs += _trgs\n            pred_trg, _ = translate_sentence_vectorized(src, src_field, trg_field, model, device)\n            for sent in pred_trg:\n                sent = [token for token in sent if token != '<unk>']\n            pred_trgs += pred_trg\n    return pred_trgs, trgs, bleu_score(pred_trgs, trgs)","metadata":{"id":"1ZdLrI0zrF6u","execution":{"iopub.status.busy":"2021-07-06T17:24:38.027578Z","iopub.execute_input":"2021-07-06T17:24:38.027898Z","iopub.status.idle":"2021-07-06T17:24:38.03562Z","shell.execute_reply.started":"2021-07-06T17:24:38.027867Z","shell.execute_reply":"2021-07-06T17:24:38.034637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, _, bleu_score = calculate_bleu_alt(test_iterator, SRC, TRG, model, device)\n\nprint(f'BLEU score = {bleu_score*100:.2f}')","metadata":{"id":"qSme29ysrGcr","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example_idx = 158\n\nsrc = vars(valid_data.examples[example_idx])['src']\ntrg = vars(valid_data.examples[example_idx])['trg']\n\nprint(f'src = {src}')\nprint(f'trg = {trg}')","metadata":{"id":"zpfZF6dErIXU","execution":{"iopub.status.busy":"2021-07-06T17:32:06.749565Z","iopub.execute_input":"2021-07-06T17:32:06.749892Z","iopub.status.idle":"2021-07-06T17:32:06.755003Z","shell.execute_reply.started":"2021-07-06T17:32:06.749861Z","shell.execute_reply":"2021-07-06T17:32:06.754162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"translation, attention = translate_sentence(src, SRC, TRG, model, device)\n\nprint(f'predicted trg = {translation}')","metadata":{"id":"JqFyYizd62_G","execution":{"iopub.status.busy":"2021-07-06T17:32:28.093819Z","iopub.execute_input":"2021-07-06T17:32:28.094136Z","iopub.status.idle":"2021-07-06T17:32:28.210979Z","shell.execute_reply.started":"2021-07-06T17:32:28.094107Z","shell.execute_reply":"2021-07-06T17:32:28.210064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"src=tokenize_ru('Сегодня я не планирую обучать глубокие сети.')\ntranslation, attention = translate_sentence(src, SRC, TRG, model, device)\n\nprint(f'predicted trg = {translation}')","metadata":{"id":"fKDA6kVdMIGE","execution":{"iopub.status.busy":"2021-07-06T18:03:05.693003Z","iopub.execute_input":"2021-07-06T18:03:05.693323Z","iopub.status.idle":"2021-07-06T18:03:05.7783Z","shell.execute_reply.started":"2021-07-06T18:03:05.693293Z","shell.execute_reply":"2021-07-06T18:03:05.777292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}